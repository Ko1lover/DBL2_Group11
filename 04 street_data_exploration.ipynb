{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the variable from the file\n",
    "with open('path_variable.pkl', 'rb') as f:\n",
    "    path_variable = pickle.load(f)\n",
    "\n",
    "# if this doesn't work just manually give the path the same value as you gave at retrieving_data.ipynb file\n",
    "# change the PATH to the location of your folder where you store the geojson file\n",
    "# PATH = '/Users/ansat.omurzakov/Desktop/TUe/Data Challenge 2/data/'\n",
    "PATH = path_variable.as_posix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the met street crimes csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(PATH + '/metropolitan-street.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve boroughs from LSOA names to be able to generalize findings in the future\n",
    "- put in appropriate timeframe when pas data contains values (2016-2023)\n",
    "- get month and year columns\n",
    "- get rid of rows where you don't have LSOA names\n",
    "- get rid of rows where you don't have long, lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_borough(value):\n",
    "    borough = re.split(r'\\d+[A-Z]', value)[0].strip()\n",
    "    return borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year and month\n",
    "data1['year'] = data1['Month'].apply(lambda x: int(x.split('-')[0]))\n",
    "data1['month'] = data1['Month'].apply(lambda x: int(x.split('-')[1]))\n",
    "\n",
    "# get data in appropriate time span\n",
    "data1 = data1[data1['year'].between(2016,2023)]\n",
    "\n",
    "# leave out the data which doesn't contain LSOA names or Longitudes or Latitudes\n",
    "data1 = data1[data1['LSOA name'].isna() == False]\n",
    "data1 = data1[(data1['Longitude'].isna()== False) | (data1['Latitude'].isna() == False)]\n",
    "\n",
    "# Retrieve boroughs from the LSOA name\n",
    "data1['borough'] = data1['LSOA name'].apply(get_borough)\n",
    "\n",
    "# Drop duplicates\n",
    "data1.drop_duplicates(keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if boroughs are controlled by the MOPAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH + '/boroughs_neighbourhoods.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Convert JSON data to a DataFrame\n",
    "boroughs_data = []\n",
    "for borough, area_codes in json_data.items():\n",
    "    for area_code in area_codes:\n",
    "        boroughs_data.append({'borough': borough, 'neighbourhood': area_code})\n",
    "\n",
    "boroughs_neighbours = pd.DataFrame(boroughs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1[data1['borough'].isin(boroughs_neighbours['borough'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns from the dataset\n",
    "data1 = data1.drop(['Crime ID', 'Reported by', 'Falls within', 'LSOA code', 'LSOA name', 'Context', 'Month'], axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning locations of crimes and finding the meaning to generalize them to make some statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['cleaned_location'] = data1['Location'].apply(lambda x: x.lower().split('on or near')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_location_v4(location):\n",
    "    \n",
    "    residential_keywords = [\n",
    "        'cottages', 'house', 'close', 'mews', 'court', \n",
    "        'place', 'building', 'village', 'villa', \n",
    "        'estate', 'palace', 'bldgs', 'yard', 'crescent',\n",
    "        'sanctuary', 'colonade', 'terrace',\n",
    "    ] # no change needed\n",
    "\n",
    "    commercial_keywords = [\n",
    "        'wharf', 'pier', 'quay', 'arcade', 'mall', 'plaza', \n",
    "        'market', 'square', 'parade', 'shopping', 'alley', \n",
    "        'post office', 'bank', 'circus', 'nightclub', 'golf', \n",
    "        'boulevard',\n",
    "    ] # no change needed\n",
    "\n",
    "\n",
    "    public_amenities_keywords = [\n",
    "        'hospital', 'school', 'college', 'academy',  \n",
    "        'park', 'education', 'church', 'sports', \n",
    "        'theatre',  'towers', 'assembly', 'police station', \n",
    "        'chantry', 'centre'\n",
    "    ]\n",
    "\n",
    "    road_pathways_keywords = list(\n",
    "        set(['track', 'bridge', 'circle', 'ring', \n",
    "            'underpass', 'tunnel', 'flyover', 'route', \n",
    "            'road', 'street', 'drive', 'path', 'link', \n",
    "            'gate', 'passage', 'slope', 'corner', 'end', \n",
    "            'mount', 'ride', 'rise', 'walk', 'way', 'quadrant', \n",
    "            'lane', 'row', 'arch', 'ring', 'avenue', 'road', \n",
    "            'street', 'knightsbridge', 'gate', 'passage',\n",
    "            'slope', 'corner', 'end','mount','ride','rise', \n",
    "            'walk',  'way', 'quadrant', 'lane','row', 'tunnel', \n",
    "            'riverside', 'approach', 'pavement','collonade', \n",
    "            'crossing', 'cross'])\n",
    "    )\n",
    "\n",
    "    transportation_keywords = [\n",
    "        'bus', 'tram', 'train', 'ferry', 'dock', 'terminal', 'aerodrome', \n",
    "        'airport', 'subway', 'bus station', 'petrol station', 'gas station', \n",
    "        'station',\n",
    "    ]\n",
    "\n",
    "    natural_features_keywords = [\n",
    "        'glade', 'dale', 'ridge', 'wood', 'forest', 'mead', 'tree', 'ground', \n",
    "        'foreshore', 'canal', 'peak', 'lake', 'orchard', 'coppice',  'wheatlands', \n",
    "        'pond','garden', 'knoll', 'copse', 'vale','field', 'meadow','hill',\n",
    "        'grove', 'green', 'lawns', 'commons', 'heath', 'mills'\n",
    "    ]\n",
    "\n",
    "\n",
    "    location_lower = location\n",
    "    \n",
    "    if any(keyword in location_lower for keyword in residential_keywords):\n",
    "        return 'Residential Area'\n",
    "    elif any(keyword in location_lower for keyword in commercial_keywords):\n",
    "        return 'Commercial Area'\n",
    "    elif any(keyword in location_lower for keyword in public_amenities_keywords):\n",
    "        return 'Public Amenities'\n",
    "    elif any(keyword in location_lower for keyword in natural_features_keywords):\n",
    "        return 'Natural Features'\n",
    "    elif any(keyword in location_lower for keyword in transportation_keywords):\n",
    "        return 'Transportation'\n",
    "    elif any(keyword in location_lower for keyword in road_pathways_keywords):\n",
    "        return 'Road_Pathway'\n",
    "    elif re.search(r'\\w\\d+', location_lower):\n",
    "        return 'Road_Pathway'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply the enhanced categorization to the dataframe\n",
    "data1['category'] = data1['cleaned_location'].apply(categorize_location_v4)\n",
    "\n",
    "# Display the updated summary of categorized data\n",
    "further_enhanced_category_counts = data1['category'].value_counts()\n",
    "print(further_enhanced_category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data1['category'])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of data per locations (in London)\",\n",
    "    xaxis_title=\"Location category\",\n",
    "    yaxis_title=\"# of crimes occuring\")\n",
    "\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the distribution of Last outcome percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = data1.groupby('Last outcome category').count().sort_values(by = 'category', ascending = False)\n",
    "cat['percentage'] = cat['category']/sum(cat['category']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat[['percentage']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping crimes in categories just as with places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_sev_idx(crime):\n",
    "    # (5)\n",
    "    if crime in ['Violence and sexual offences', 'Criminal damage and arson']:\n",
    "        return 'Violent crime'\n",
    "\n",
    "    # (4)\n",
    "    elif crime in ['Burglary', 'Vehicle crime', 'Robbery', 'Theft from the person',  'Shoplifting', 'Bicycle theft']:\n",
    "        return 'Property damage'\n",
    "    \n",
    "    # (3) - \n",
    "    elif crime in [ 'Public order', 'Anti-social behaviour',  'Other crime']:\n",
    "        return 'Public order crime'\n",
    "\n",
    "    # (2)\n",
    "    elif crime in ['Drugs', 'Possession of weapons']:\n",
    "        return 'Drugs and weapons'\n",
    "    \n",
    "    # (1)\n",
    "    elif crime in ['Other crime', 'Other theft']:\n",
    "        return 'Miscellaneous crime'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting quarter from the data since the PAS data is given with years and quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_quarter(month):\n",
    "    if month in [1,2,3]:\n",
    "        return 1\n",
    "    elif month in [4,5,6]:\n",
    "        return 2\n",
    "    elif month in [7,8,9]:\n",
    "        return 3\n",
    "    elif month in [10,11,12]:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['crime_group'] = data1['Crime type'].apply(give_sev_idx)\n",
    "data1['quarter'] = data1['month'].apply(give_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a street dataframe for merging with file we created at data_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_merge = data1[['Crime type', 'Last outcome category', 'borough', 'quarter', 'year', 'category', 'crime_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['Crime type', 'Last outcome category', 'category', 'crime_group']\n",
    "dummies = pd.get_dummies(data_for_merge[columns_to_count])\n",
    "street_cleaned_with_dummies = pd.concat([data_for_merge, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = street_cleaned_with_dummies.drop(['Crime type', 'Last outcome category', 'category', 'crime_group'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = wrap.groupby(['borough', 'year', 'quarter']).sum().reset_index()\n",
    "wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_with_sas = pd.read_csv(PATH + '/PAS_with_SAS.csv')\n",
    "pas_with_sas = pas_with_sas.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the file, so you could delete the metropolitan-street.csv which weights around 3 gb, creating a smaller in volumne file for your RAM to be easier to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_with_sas.merge(wrap, on = ['borough', 'year', 'quarter']).to_csv(PATH + '/final_latest_pas_with_sas_with_street_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pss = pd.read_csv(PATH + '/FINAL_agg_Dataset.csv')\n",
    "pss.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphics indicating at which locations crimes mainly happening per borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving columns for places categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipap = []\n",
    "for column in pss.columns:\n",
    "    if column.startswith('category'):\n",
    "        pipap.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unscaled graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siki = pss[pipap + ['year', 'quarter', 'borough']]\n",
    "\n",
    "# Create 'Year-Quarter' column\n",
    "siki['Year-Quarter'] = siki['year'].astype(str) + ' Q' + siki['quarter'].astype(str)\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    'category_Commercial Area', \n",
    "    'category_Natural Features',\n",
    "    'category_Other', \n",
    "    'category_Public Amenities',\n",
    "    'category_Residential Area', \n",
    "    'category_Transportation',\n",
    "    'category_Road_Pathway'\n",
    "]\n",
    "\n",
    "# Get the unique boroughs\n",
    "boroughs = siki['borough'].unique()\n",
    "\n",
    "# Create a consistent color palette\n",
    "colors = px.colors.qualitative.Plotly\n",
    "color_mapping = {category: colors[i % len(colors)] for i, category in enumerate(categories)}\n",
    "\n",
    "# Create subplot figure with shared x and y axes\n",
    "fig = make_subplots(rows=4, cols=8, subplot_titles=boroughs)\n",
    "\n",
    "# Iterate over each borough and add a subplot\n",
    "for i, borough in enumerate(boroughs):\n",
    "    # Group by 'Year-Quarter' and sum the counts for the current borough\n",
    "    df_grouped = siki[siki['borough'] == borough].groupby('Year-Quarter')[categories].sum().reset_index()\n",
    "    \n",
    "    # Unpivot the grouped DataFrame to long format\n",
    "    df_long = df_grouped.melt(id_vars=['Year-Quarter'], \n",
    "                              value_vars=categories,\n",
    "                              var_name='Category', \n",
    "                              value_name='Count')\n",
    "    \n",
    "    # Rename categories to remove 'category_' prefix for cleaner labels\n",
    "    df_long['Category'] = df_long['Category'].str.replace('category_', '')\n",
    "    \n",
    "    # Determine subplot row and column\n",
    "    row = i // 8 + 1\n",
    "    col = i % 8 + 1\n",
    "    \n",
    "    # Add traces for each category with consistent colors\n",
    "    for category in df_long['Category'].unique():\n",
    "        category_data = df_long[df_long['Category'] == category]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=category_data['Year-Quarter'], y=category_data['Count'], \n",
    "                       mode='lines+markers', name=category, legendgroup=category,\n",
    "                       marker=dict(color=color_mapping['category_' + category]), # Use consistent color\n",
    "                       showlegend=(i == 0)),\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    # Update subplot title\n",
    "    fig.update_xaxes(title_text=\"Year-Quarter\", row=row, col=col)\n",
    "    fig.update_yaxes(title_text=\"Count\", row=row, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1500, width=3000,\n",
    "    title_text=\"Crime Count per Category by Year and Quarter for All Boroughs\",\n",
    "    showlegend=True,\n",
    "    title_font_size=30,\n",
    "    title_font_family='bold'\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled similarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'Year-Quarter' column\n",
    "siki['Year-Quarter'] = siki['year'].astype(str) + ' Q' + siki['quarter'].astype(str)\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    'category_Commercial Area', \n",
    "    'category_Natural Features',\n",
    "    'category_Other', \n",
    "    'category_Public Amenities',\n",
    "    'category_Residential Area', \n",
    "    'category_Transportation',\n",
    "    'category_Road_Pathway'\n",
    "]\n",
    "\n",
    "# Get the unique boroughs\n",
    "boroughs = siki['borough'].unique()\n",
    "\n",
    "# Create a consistent color palette\n",
    "colors = px.colors.qualitative.Plotly\n",
    "color_mapping = {category: colors[i % len(colors)] for i, category in enumerate(categories)}\n",
    "\n",
    "# Determine the overall x and y axis ranges\n",
    "overall_min_x = siki['Year-Quarter'].min()\n",
    "overall_max_x = siki['Year-Quarter'].max()\n",
    "overall_min_y = min(siki[['category_Commercial Area', \n",
    "    'category_Natural Features',\n",
    "    'category_Other', \n",
    "    'category_Public Amenities',\n",
    "    'category_Residential Area', \n",
    "    'category_Transportation',\n",
    "    'category_Road_Pathway']].min().to_list())\n",
    "overall_max_y = max(siki[[ 'category_Commercial Area', \n",
    "    'category_Natural Features',\n",
    "    'category_Other', \n",
    "    'category_Public Amenities',\n",
    "    'category_Residential Area', \n",
    "    'category_Transportation',\n",
    "    'category_Road_Pathway']].max().to_list())\n",
    "\n",
    "# Create subplot figure with shared x and y axes\n",
    "fig = make_subplots(rows=4, cols=8, subplot_titles=boroughs)\n",
    "\n",
    "# Iterate over each borough and add a subplot\n",
    "for i, borough in enumerate(boroughs):\n",
    "    # Group by 'Year-Quarter' and sum the counts for the current borough\n",
    "    df_grouped = siki[siki['borough'] == borough].groupby('Year-Quarter')[categories].sum().reset_index()\n",
    "    \n",
    "    # Unpivot the grouped DataFrame to long format\n",
    "    df_long = df_grouped.melt(id_vars=['Year-Quarter'], \n",
    "                              value_vars=categories,\n",
    "                              var_name='Category', \n",
    "                              value_name='Count')\n",
    "    \n",
    "    # Rename categories to remove 'category_' prefix for cleaner labels\n",
    "    df_long['Category'] = df_long['Category'].str.replace('category_', '')\n",
    "    \n",
    "    # Determine subplot row and column\n",
    "    row = i // 8 + 1\n",
    "    col = i % 8 + 1\n",
    "    \n",
    "    # Add traces for each category with consistent colors\n",
    "    for category in df_long['Category'].unique():\n",
    "        category_data = df_long[df_long['Category'] == category]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=category_data['Year-Quarter'], y=category_data['Count'], \n",
    "                       mode='lines+markers', name=category, legendgroup=category,\n",
    "                       marker=dict(color=color_mapping['category_' + category]), # Use consistent color\n",
    "                       showlegend=(i == 0)),\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    # Update subplot title\n",
    "    fig.update_xaxes(title_text=\"Year-Quarter\", range=[overall_min_x, overall_max_x], row=row, col=col)\n",
    "    fig.update_yaxes(title_text=\"Count\", range=[overall_min_y, overall_max_y], row=row, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1500, width=2500,\n",
    "    title_text=\"Crime Count per Location Category by Year and Quarter for All Boroughs\",\n",
    "    showlegend=True,\n",
    "    title_font_size=30,\n",
    "    title_font_family='bold'\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphics indicating at what kind of crimes mainly happening per borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving crime groups in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_group = []\n",
    "for column in pss.columns:\n",
    "    if column.startswith('crime_group'):\n",
    "        crime_group.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unscaled grpahic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siki = pss[crime_group + ['year', 'quarter', 'borough']]\n",
    "\n",
    "# Create 'Year-Quarter' column\n",
    "siki['Year-Quarter'] = siki['year'].astype(str) + ' Q' + siki['quarter'].astype(str)\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    'crime_group_Drugs and weapons',\n",
    "    'crime_group_Miscellaneous crime',\n",
    "    'crime_group_Property damage',\n",
    "    'crime_group_Public order crime',\n",
    "    'crime_group_Violent crime'\n",
    "]\n",
    "\n",
    "# Get the unique boroughs\n",
    "boroughs = siki['borough'].unique()\n",
    "\n",
    "# Create a consistent color palette\n",
    "colors = px.colors.qualitative.Plotly\n",
    "color_mapping = {category: colors[i % len(colors)] for i, category in enumerate(categories)}\n",
    "\n",
    "# Create subplot figure with shared x and y axes\n",
    "fig = make_subplots(rows=4, cols=8, subplot_titles=boroughs)\n",
    "\n",
    "# Iterate over each borough and add a subplot\n",
    "for i, borough in enumerate(boroughs):\n",
    "    # Group by 'Year-Quarter' and sum the counts for the current borough\n",
    "    df_grouped = siki[siki['borough'] == borough].groupby('Year-Quarter')[categories].sum().reset_index()\n",
    "    \n",
    "    # Unpivot the grouped DataFrame to long format\n",
    "    df_long = df_grouped.melt(id_vars=['Year-Quarter'], \n",
    "                              value_vars=categories,\n",
    "                              var_name='Category', \n",
    "                              value_name='Count')\n",
    "    \n",
    "    # Rename categories to remove 'category_' prefix for cleaner labels\n",
    "    df_long['Category'] = df_long['Category'].str.replace('crime_', '')\n",
    "    \n",
    "    # Determine subplot row and column\n",
    "    row = i // 8 + 1\n",
    "    col = i % 8 + 1\n",
    "    \n",
    "    # Add traces for each category with consistent colors\n",
    "    for category in df_long['Category'].unique():\n",
    "        category_data = df_long[df_long['Category'] == category]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=category_data['Year-Quarter'], y=category_data['Count'], \n",
    "                       mode='lines+markers', name=category, legendgroup=category,\n",
    "                       marker=dict(color=color_mapping['crime_' + category]), # Use consistent color\n",
    "                       showlegend=(i == 0)),\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    # Update subplot title\n",
    "    # fig.update_xaxes(title_text=\"Year-Quarter\", range=[overall_min_x, overall_max_x], row=row, col=col)\n",
    "    # fig.update_yaxes(title_text=\"Count\", range=[overall_min_y, overall_max_y], row=row, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1500, width=3000,\n",
    "    title_text=\"Crime Count per Category by Year and Quarter for All Boroughs\",\n",
    "    showlegend=True,\n",
    "    title_font_size=30,\n",
    "    title_font_family='bold'\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled similarly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'Year-Quarter' column\n",
    "siki['Year-Quarter'] = siki['year'].astype(str) + ' Q' + siki['quarter'].astype(str)\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    'crime_group_Drugs and weapons',\n",
    "    'crime_group_Miscellaneous crime',\n",
    "    'crime_group_Property damage',\n",
    "    'crime_group_Public order crime',\n",
    "    'crime_group_Violent crime'\n",
    "]\n",
    "\n",
    "# Get the unique boroughs\n",
    "boroughs = siki['borough'].unique()\n",
    "\n",
    "# Create a consistent color palette\n",
    "colors = px.colors.qualitative.Plotly\n",
    "color_mapping = {category: colors[i % len(colors)] for i, category in enumerate(categories)}\n",
    "\n",
    "overall_min_x = siki['Year-Quarter'].min()\n",
    "overall_max_x = siki['Year-Quarter'].max()\n",
    "overall_min_y = min(siki[['crime_group_Drugs and weapons',\n",
    "    'crime_group_Miscellaneous crime',\n",
    "    'crime_group_Property damage',\n",
    "    'crime_group_Public order crime',\n",
    "    'crime_group_Violent crime']].min().to_list())\n",
    "overall_max_y = max(siki[['crime_group_Drugs and weapons',\n",
    "    'crime_group_Miscellaneous crime',\n",
    "    'crime_group_Property damage',\n",
    "    'crime_group_Public order crime',\n",
    "    'crime_group_Violent crime']].max().to_list())\n",
    "\n",
    "# Determine the overall x and y axis ranges\n",
    "overall_min_x = siki['Year-Quarter'].min()\n",
    "overall_max_x = siki['Year-Quarter'].max()\n",
    "overall_min_y = min(siki[crime_group].min().to_list())\n",
    "overall_max_y = max(siki[crime_group].max().to_list())\n",
    "\n",
    "# Create subplot figure with shared x and y axes\n",
    "fig = make_subplots(rows=4, cols=8, subplot_titles=boroughs)\n",
    "\n",
    "# Iterate over each borough and add a subplot\n",
    "for i, borough in enumerate(boroughs):\n",
    "    # Group by 'Year-Quarter' and sum the counts for the current borough\n",
    "    df_grouped = siki[siki['borough'] == borough].groupby('Year-Quarter')[categories].sum().reset_index()\n",
    "    \n",
    "    # Unpivot the grouped DataFrame to long format\n",
    "    df_long = df_grouped.melt(id_vars=['Year-Quarter'], \n",
    "                              value_vars=categories,\n",
    "                              var_name='Category', \n",
    "                              value_name='Count')\n",
    "    \n",
    "    # Rename categories to remove 'category_' prefix for cleaner labels\n",
    "    df_long['Category'] = df_long['Category'].str.replace('crime_', '')\n",
    "    \n",
    "    # Determine subplot row and column\n",
    "    row = i // 8 + 1\n",
    "    col = i % 8 + 1\n",
    "    \n",
    "    # Add traces for each category with consistent colors\n",
    "    for category in df_long['Category'].unique():\n",
    "        category_data = df_long[df_long['Category'] == category]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=category_data['Year-Quarter'], y=category_data['Count'], \n",
    "                       mode='lines+markers', name=category, legendgroup=category,\n",
    "                       marker=dict(color=color_mapping['crime_' + category]), # Use consistent color\n",
    "                       showlegend=(i == 0)),\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    # Update subplot title\n",
    "    # fig.update_xaxes(title_text=\"Year-Quarter\", row=row, col=col)\n",
    "    # fig.update_yaxes(title_text=\"Count\", row=row, col=col)\n",
    "    fig.update_xaxes(title_text=\"Year-Quarter\", range=[overall_min_x, overall_max_x], row=row, col=col)\n",
    "    fig.update_yaxes(title_text=\"Count\", range=[overall_min_y, overall_max_y], row=row, col=col)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1500, width=3000,\n",
    "    title_text=\"Crime Count per Crime Category by Year and Quarter for All Boroughs\",\n",
    "    showlegend=True,\n",
    "    title_font_size=30,\n",
    "    title_font_family='bold'\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating corrleation heatmap throughout 2016-2023 time period, between the most significant features at crime groups and crime locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_get = pss[pipap+crime_group + ['year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipap = ['category_Natural Features',\n",
    " 'category_Residential Area',\n",
    " 'category_Road_Pathway',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_group = ['crime_group_Property damage','crime_group_Public order crime','crime_group_Violent crime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Initialize a dictionary to store correlation matrices\n",
    "correlation_matrices = {}\n",
    "\n",
    "# Loop over each year and calculate the correlation matrix\n",
    "for i, year in enumerate(to_get['year'].unique()):\n",
    "    year_data = to_get[to_get['year'] == year]  # Ensure year_data is a DataFrame\n",
    "    correlation_matrix = year_data[pipap + crime_group].corr()\n",
    "    correlation_matrices[year] = correlation_matrix\n",
    "\n",
    "    # Extract the part of the correlation matrix that is relevant\n",
    "    correlation_submatrix = correlation_matrix.loc[pipap, crime_group]\n",
    "\n",
    "    # Plot the heatmap for the current year\n",
    "    sns.heatmap(correlation_submatrix, annot=True, fmt='.2f', cmap='magma', cbar=True, ax=axes[i])\n",
    "    axes[i].set_title(f\"Correlation Matrix for {year}\")\n",
    "    # Rotate x-axis tick labels and align them properly\n",
    "    plt.setp(axes[i].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "    # Ensure y-axis tick labels remain horizontal\n",
    "    plt.setp(axes[i].get_yticklabels(), rotation=0, ha='right')\n",
    "    # axes[i].tick_params(axis='y', rotation=0)\n",
    "\n",
    "# Adjust layout\n",
    "fig.suptitle('Correlation matrices for Crime groups and Places', weight = 'bold', size = 16)\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the significance level as well as the correlation coefficient between different features and Confidence of the Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data (replace with your actual data)\n",
    "# Assume trust and crime_type are pandas Series with datetime index\n",
    "trust = pss[(pss['year'].between(2017, 2023)) &(pss['borough'] == 'Richmond upon Thames')]['Contact ward officer']\n",
    "crime_type = pss[(pss['year'].between(2017, 2023))& (pss['borough'] == 'Richmond upon Thames')]['\"Good Job\" local']\n",
    "\n",
    "# Define window size for rolling correlation\n",
    "window_size = 3  # 12 months per year\n",
    "\n",
    "# Calculate rolling correlation\n",
    "rolling_correlation = trust.rolling(window=window_size).corr(crime_type)\n",
    "\n",
    "# Calculate statistical significance (p-values)\n",
    "rolling_p_values = trust.rolling(window=window_size).apply(lambda x: pearsonr(x, crime_type.iloc[-len(x):])[1], raw=True)\n",
    "\n",
    "# Plot rolling correlation\n",
    "plt.figure(figsize=(10, 6))\n",
    "rolling_correlation.plot(label='Rolling Correlation (Trust vs Crime Type)')\n",
    "plt.axhline(y=0, color='gray', linestyle='--')\n",
    "plt.title('Rolling Correlation between Trust and Crime Type')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot statistical significance\n",
    "plt.figure(figsize=(10, 6))\n",
    "rolling_p_values.plot(label='Rolling P-Values (Statistical Significance)')\n",
    "plt.axhline(y=0.05, color='r', linestyle='--', label='Significance Threshold (p=0.05)')\n",
    "plt.title('Statistical Significance of Rolling Correlation')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('P-Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = pd.concat([rolling_p_values, rolling_correlation], axis = 1)\n",
    "fun = fun.rename(columns = {'Contact ward officer': 'p_value', 0: 'correlation value'})\n",
    "fun[fun['p_value'] <= 0.05].median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

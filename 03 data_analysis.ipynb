{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a4ba603734e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "from shapely.geometry import Point, Polygon\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the variable from the file\n",
    "with open('path_variable.pkl', 'rb') as f:\n",
    "    path_variable = pickle.load(f)\n",
    "\n",
    "PATH = path_variable.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this doesn't work just manually give the path the same value as you gave at retrieving_data.ipynb file\n",
    "# change the PATH to the location of your folder where you store the geojson file\n",
    "PATH = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "sas = pd.read_csv(PATH + '/metropolitan-stop-and-search.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data cleaning before using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas = sas[(sas['Longitude'].isna() == False) & (sas['Latitude'].isna() == False) & (sas['Type']!= 'Vehicle search')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Assign boroughs for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH + '/neighborhood_boundaries.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Convert JSON data to a DataFrame\n",
    "boroughs_data = []\n",
    "for borough, area_codes in json_data.items():\n",
    "    for lst in area_codes:\n",
    "        for neighbourhood, polygon in lst.items():\n",
    "            boroughs_data.append({'borough': borough, 'neighbourhood': neighbourhood, 'polygon': polygon})\n",
    "\n",
    "boroughs_neighbours = pd.DataFrame(boroughs_data)\n",
    "boroughs_neighbours['polygon'] = boroughs_neighbours['polygon'].apply(lambda x: Polygon(x))\n",
    "boroughs_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_borough_name(data):\n",
    "    lat, long = data\n",
    "    point = Point(lat, long)\n",
    "    is_within = boroughs_neighbours['polygon'].apply(lambda x: point.within(x))\n",
    "    if len(boroughs_neighbours[is_within]['borough'].values) > 0:\n",
    "        borough_name = boroughs_neighbours[is_within]['borough'].values[0]\n",
    "        return borough_name\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = sas[['Latitude', 'Longitude']].drop_duplicates(keep = 'first')\n",
    "locs['borough'] = locs.progress_apply(get_borough_name, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas = sas.merge(locs, on = ['Latitude', 'Longitude'], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing irrelevant columns from the stop and search dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_cleaned = sas.drop(['Part of a policing operation', 'Policing operation', 'Outcome linked to object of search', 'Removal of more than just outer clothing'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating column with generalized ehtnicities so we would have 1 ehtnicity column with as much info as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to interpolate values when officer defined ethnicity is Other and Self-defined ethnicity is not, such that we would have more data.\n",
    "def group_ethnicity(data):\n",
    "    if (data['Officer-defined ethnicity'] == 'Other' or not isinstance(data['Officer-defined ethnicity'], str)) and isinstance(data['Self-defined ethnicity'], str):\n",
    "        if re.match(r\"^(White)\", data['Self-defined ethnicity']): # white\n",
    "            return 'White'\n",
    "        elif re.match(r\"^(Black)\", data['Self-defined ethnicity']): # black\n",
    "            return 'Black'\n",
    "        elif re.match(r\"^(Asian)|(Chinese)\", data['Self-defined ethnicity']): # asian\n",
    "            return 'Asian'\n",
    "        elif re.match(r\"^(Mixed)|\",data['Self-defined ethnicity']): # mixed\n",
    "            return 'Mixed'\n",
    "        elif re.match(r\"^(Other)|(Not)\",data['Self-defined ethnicity']): # other/unknown/not_stated\n",
    "            return 'Other'\n",
    "    else:\n",
    "        return data['Officer-defined ethnicity']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_cleaned['generalized_ethnicity'] = sas_cleaned.apply(group_ethnicity, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_cleaned = sas_cleaned[sas_cleaned['generalized_ethnicity'].isna() == False]\n",
    "sas_cleaned = sas_cleaned[sas_cleaned['borough'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a new dataframe which will be merged with other dataframes, with no irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_for_merge = sas_cleaned.drop(['Type', 'Latitude', 'Longitude', 'Self-defined ethnicity', 'Officer-defined ethnicity'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding new columns for month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_for_merge['year'] = pd.to_datetime(sas_for_merge['Date']).dt.year\n",
    "sas_for_merge['month'] = pd.to_datetime(sas_for_merge['Date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_for_merge = sas_for_merge[sas_for_merge['year'].between(2016,2023)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_for_merge = sas_for_merge.drop('Date', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_quarter(month):\n",
    "    if month in [1,2,3]:\n",
    "        return 1\n",
    "    elif month in [4,5,6]:\n",
    "        return 2\n",
    "    elif month in [7,8,9]:\n",
    "        return 3\n",
    "    elif month in [10,11,12]:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_for_merge['quarter'] = sas_for_merge['month'].apply(give_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_count = ['Gender', 'Age range', 'generalized_ethnicity', 'Legislation', 'Object of search', 'Outcome']\n",
    "dummies = pd.get_dummies(sas_for_merge[columns_to_count])\n",
    "sas_cleaned_with_dummies = pd.concat([sas_for_merge, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = sas_cleaned_with_dummies.drop(['Gender', 'Age range', 'generalized_ethnicity', 'Legislation', 'Object of search', 'Outcome', 'month'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = wrap.groupby(['borough', 'year', 'quarter']).sum().reset_index()\n",
    "wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imoprting new dataframe with PAS data from 2016-2023 (not questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas = pd.read_csv(PATH + '/PAS_borough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table\n",
    "pivot_table = pas.pivot_table(index=['Date', 'Borough'], columns='Measure', values='Proportion', fill_value=None)\n",
    "\n",
    "# Reset index to make it columns again\n",
    "pivot_table.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table['month'] = pd.to_datetime(pivot_table['Date']).dt.month\n",
    "pivot_table['day'] = pd.to_datetime(pivot_table['Date']).dt.day\n",
    "pivot_table['year'] = pd.to_datetime(pivot_table['Date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = pivot_table[pivot_table['year'].between(2016, 2024)].reset_index()\n",
    "pivot_table = pivot_table.drop(['index', 'Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table['Borough'] = pivot_table['Borough'].apply(lambda x: 'Westminster'  if x == 'City of Westminster' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table['quarter'] = pivot_table['month'].apply(give_quarter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_for_merge= pivot_table[['Borough', '\"Good Job\" local', 'Trust MPS', 'Contact ward officer', 'Informed local', 'Listen to concerns', 'Relied on to be there', 'Treat everyone fairly', 'Understand issues', 'quarter', 'year']]\n",
    "pivot_for_merge = pivot_for_merge.rename(columns = {'Borough': 'borough'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets of PAS and Stop and Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pivot_for_merge.merge(wrap, on = ['borough', 'year', 'quarter'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(PATH + '/PAS_with_SAS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of change of scores for Trust and Confidence in MOPAC throughout 2016 Q2 -2023 Q4 period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['year-quarter'] = all_data['year-quarter'] = all_data['year'].astype(str) + '-Q' + all_data['quarter'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=8, figsize=(25, 15))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "x_min = all_data['year-quarter'].min()\n",
    "x_max = all_data['year-quarter'].max()\n",
    "y_min = all_data['Trust MPS'].min()\n",
    "y_max = all_data['Trust MPS'].max()\n",
    "\n",
    "all_xticks = sorted(all_data['year-quarter'].unique())\n",
    "step = max(1, len(all_xticks) // 10)  # Adjust step to show fewer ticks\n",
    "xticks = all_xticks[::step]\n",
    "\n",
    "# Iterate through each borough and create a line chart\n",
    "boroughs = all_data['borough'].unique()\n",
    "for i, borough in enumerate(boroughs):\n",
    "    row = i // 8\n",
    "    col = i % 8\n",
    "    \n",
    "    # Filter data for the current borough\n",
    "    data = all_data[all_data['borough'] == borough]\n",
    "    \n",
    "    # Plot the line chart\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(data['year-quarter'], data['Trust MPS'], marker='o', linestyle='-')\n",
    "    ax.set_title(borough)\n",
    "    ax.set_xlim(x_min, x_max)  # Set x-axis range\n",
    "    ax.set_ylim(y_min, y_max)  # Set y-axis range\n",
    "    ax.set_xlabel('Year-Quarter')\n",
    "    ax.set_ylabel('Trust')\n",
    "    ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better readability\n",
    "    \n",
    "    # Set custom ticks\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticks, rotation=45, ha='right')\n",
    "    \n",
    "\n",
    "# Adjust layout\n",
    "fig.suptitle('Trust in all boroughs observed by MOPAC', fontsize = 30, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=8, figsize=(25, 15))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "x_min = all_data['year-quarter'].min()\n",
    "x_max = all_data['year-quarter'].max()\n",
    "y_min = all_data['\"Good Job\" local'].min()\n",
    "y_max = all_data['\"Good Job\" local'].max()\n",
    "\n",
    "all_xticks = sorted(all_data['year-quarter'].unique())\n",
    "step = max(1, len(all_xticks) // 10)  # Adjust step to show fewer ticks\n",
    "xticks = all_xticks[::step]\n",
    "\n",
    "# Iterate through each borough and create a line chart\n",
    "boroughs = all_data['borough'].unique()\n",
    "for i, borough in enumerate(boroughs):\n",
    "    row = i // 8\n",
    "    col = i % 8\n",
    "    \n",
    "    # Filter data for the current borough\n",
    "    data = all_data[all_data['borough'] == borough]\n",
    "    \n",
    "    # Plot the line chart\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(data['year-quarter'], data['\"Good Job\" local'], marker='o', linestyle='-')\n",
    "    ax.set_title(borough)\n",
    "    ax.set_xlim(x_min, x_max)  # Set x-axis range\n",
    "    ax.set_ylim(y_min, y_max)  # Set y-axis range\n",
    "    ax.set_xlabel('Year-Quarter')\n",
    "    ax.set_ylabel('Confidence')\n",
    "    ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better readability\n",
    "    \n",
    "    # Set custom ticks\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticks, rotation=45, ha='right')\n",
    "    \n",
    "\n",
    "# Adjust layout\n",
    "fig.suptitle('Confidence in all boroughs observed by MOPAC', fontsize = 30, fontweight = 'bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
